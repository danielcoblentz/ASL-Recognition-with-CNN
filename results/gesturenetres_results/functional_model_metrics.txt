┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)      │ (None, 64, 64, 1)         │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_1 (Conv2D)             │ (None, 64, 64, 16)        │             800 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation (Activation)       │ (None, 64, 64, 16)        │               0 │ conv2d_1[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization           │ (None, 64, 64, 16)        │              64 │ activation[0][0]           │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_2 (Conv2D)             │ (None, 64, 64, 16)        │          12,560 │ batch_normalization[0][0]  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_1 (Activation)     │ (None, 64, 64, 16)        │               0 │ conv2d_2[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_1         │ (None, 64, 64, 16)        │              64 │ activation_1[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d (Conv2D)               │ (None, 64, 64, 16)        │              32 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add (Add)                     │ (None, 64, 64, 16)        │               0 │ batch_normalization_1[0][… │
│                               │                           │                 │ conv2d[0][0]               │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d (MaxPooling2D)  │ (None, 32, 32, 16)        │               0 │ add[0][0]                  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout (Dropout)             │ (None, 32, 32, 16)        │               0 │ max_pooling2d[0][0]        │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_4 (Conv2D)             │ (None, 32, 32, 32)        │           4,640 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_2 (Activation)     │ (None, 32, 32, 32)        │               0 │ conv2d_4[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_2         │ (None, 32, 32, 32)        │             128 │ activation_2[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_5 (Conv2D)             │ (None, 32, 32, 32)        │           9,248 │ batch_normalization_2[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_3 (Activation)     │ (None, 32, 32, 32)        │               0 │ conv2d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_3         │ (None, 32, 32, 32)        │             128 │ activation_3[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_3 (Conv2D)             │ (None, 32, 32, 32)        │             544 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_1 (Add)                   │ (None, 32, 32, 32)        │               0 │ batch_normalization_3[0][… │
│                               │                           │                 │ conv2d_3[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d_1               │ (None, 16, 16, 32)        │               0 │ add_1[0][0]                │
│ (MaxPooling2D)                │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_1 (Dropout)           │ (None, 16, 16, 32)        │               0 │ max_pooling2d_1[0][0]      │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_7 (Conv2D)             │ (None, 16, 16, 64)        │          18,496 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_4 (Activation)     │ (None, 16, 16, 64)        │               0 │ conv2d_7[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_4         │ (None, 16, 16, 64)        │             256 │ activation_4[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_6 (Conv2D)             │ (None, 16, 16, 64)        │           2,112 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_2 (Add)                   │ (None, 16, 16, 64)        │               0 │ batch_normalization_4[0][… │
│                               │                           │                 │ conv2d_6[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d_2               │ (None, 8, 8, 64)          │               0 │ add_2[0][0]                │
│ (MaxPooling2D)                │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_2 (Dropout)           │ (None, 8, 8, 64)          │               0 │ max_pooling2d_2[0][0]      │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ flatten (Flatten)             │ (None, 4096)              │               0 │ dropout_2[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, 128)               │         524,416 │ flatten[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_5 (Activation)     │ (None, 128)               │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_5         │ (None, 128)               │             512 │ activation_5[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_1 (Dense)               │ (None, 9)                 │           1,161 │ batch_normalization_5[0][… │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 575,161 (2.19 MB)
 Trainable params: 574,585 (2.19 MB)
 Non-trainable params: 576 (2.25 KB)
None
/opt/anaconda3/envs/CS428/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 28s 41ms/step - accuracy: 0.3325 - loss: 1.8614 - val_accuracy: 0.3540 - val_loss: 2.9366
Epoch 2/75
2024-11-14 20:50:57.751228: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
  1/653 ━━━━━━━━━━━━━━━━━━━━ 25s 39ms/step - accuracy: 0.5000 - loss: 1.3428/opt/anaconda3/envs/CS428/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self.gen.throw(typ, value, traceback)
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5000 - loss: 1.3428 - val_accuracy: 0.3465 - val_loss: 3.0366
Epoch 3/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 27s 42ms/step - accuracy: 0.5971 - loss: 1.1775 - val_accuracy: 0.9099 - val_loss: 0.3604
Epoch 4/75
2024-11-14 20:51:26.550083: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5000 - loss: 1.7716 - val_accuracy: 0.9185 - val_loss: 0.3516
Epoch 5/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 44ms/step - accuracy: 0.6844 - loss: 0.9531 - val_accuracy: 0.8629 - val_loss: 0.3842
Epoch 6/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.3180 - val_accuracy: 0.8738 - val_loss: 0.3569
Epoch 7/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 28s 43ms/step - accuracy: 0.7290 - loss: 0.7973 - val_accuracy: 0.7539 - val_loss: 0.6286
Epoch 8/75
2024-11-14 20:52:26.293760: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.6791 - val_accuracy: 0.7585 - val_loss: 0.6167
Epoch 9/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 44ms/step - accuracy: 0.7741 - loss: 0.6819 - val_accuracy: 0.6426 - val_loss: 1.0441
Epoch 10/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 0.8920 - val_accuracy: 0.6575 - val_loss: 0.9723
Epoch 11/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.8168 - loss: 0.5700 - val_accuracy: 0.7544 - val_loss: 0.8035
Epoch 12/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.5514 - val_accuracy: 0.7562 - val_loss: 0.7922
Epoch 13/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 45ms/step - accuracy: 0.8354 - loss: 0.5102 - val_accuracy: 0.7401 - val_loss: 0.8488
Epoch 14/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4671 - val_accuracy: 0.7458 - val_loss: 0.8498
Epoch 15/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 45ms/step - accuracy: 0.8484 - loss: 0.4458 - val_accuracy: 0.8170 - val_loss: 0.7742
Epoch 16/75
2024-11-14 20:54:29.378247: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5000 - loss: 1.7008 - val_accuracy: 0.8164 - val_loss: 0.7824
Epoch 17/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 45ms/step - accuracy: 0.8572 - loss: 0.4427 - val_accuracy: 0.8181 - val_loss: 0.6475
Epoch 18/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0781 - val_accuracy: 0.8153 - val_loss: 0.6798
Epoch 19/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 47ms/step - accuracy: 0.8629 - loss: 0.4143 - val_accuracy: 0.9306 - val_loss: 0.1977
Epoch 20/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4816 - val_accuracy: 0.9392 - val_loss: 0.1856
Epoch 21/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 47ms/step - accuracy: 0.8748 - loss: 0.3805 - val_accuracy: 0.9025 - val_loss: 0.2532
Epoch 22/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.1504 - val_accuracy: 0.9019 - val_loss: 0.2534
Epoch 23/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 47ms/step - accuracy: 0.8943 - loss: 0.3295 - val_accuracy: 0.8193 - val_loss: 0.7125
Epoch 24/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.4797 - val_accuracy: 0.8336 - val_loss: 0.6702
Epoch 25/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 48ms/step - accuracy: 0.8697 - loss: 0.3904 - val_accuracy: 0.8394 - val_loss: 0.5478
Epoch 26/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4354 - val_accuracy: 0.8480 - val_loss: 0.5216
Epoch 27/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 540s 828ms/step - accuracy: 0.8685 - loss: 0.4022 - val_accuracy: 0.7998 - val_loss: 0.6995
Epoch 28/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5000 - loss: 1.1438 - val_accuracy: 0.7975 - val_loss: 0.6947
Epoch 29/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 72s 111ms/step - accuracy: 0.8958 - loss: 0.3381 - val_accuracy: 0.9237 - val_loss: 0.1996
Epoch 30/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.1446 - val_accuracy: 0.9203 - val_loss: 0.2156
Epoch 31/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 2026s 3s/step - accuracy: 0.9059 - loss: 0.2728 - val_accuracy: 0.8617 - val_loss: 0.4567
Epoch 32/75
  1/653 ━━━━━━━━━━━━━━━━━━━━ 29s 45ms/step - accuracy: 1.0000 - loss: 0.03602024-11-14 21:41:11.290926: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0360 - val_accuracy: 0.8635 - val_loss: 0.4472
Epoch 33/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 230s 353ms/step - accuracy: 0.9186 - loss: 0.2510 - val_accuracy: 0.9552 - val_loss: 0.2073
Epoch 34/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0856 - val_accuracy: 0.9558 - val_loss: 0.2017
Epoch 35/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.9265 - loss: 0.2302 - val_accuracy: 0.9145 - val_loss: 0.2417
Epoch 36/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9168 - val_loss: 0.2334
Epoch 37/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.9176 - loss: 0.2549 - val_accuracy: 0.8721 - val_loss: 0.3793
Epoch 38/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.3313 - val_accuracy: 0.8698 - val_loss: 0.3986
Epoch 39/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.9240 - loss: 0.2352 - val_accuracy: 0.4360 - val_loss: 2.7991
Epoch 40/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.1590 - val_accuracy: 0.4492 - val_loss: 2.7009
Epoch 41/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 47ms/step - accuracy: 0.9089 - loss: 0.2574 - val_accuracy: 0.8893 - val_loss: 0.3196
Epoch 42/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8881 - val_loss: 0.3273
Epoch 43/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 47ms/step - accuracy: 0.9230 - loss: 0.2378 - val_accuracy: 0.8181 - val_loss: 0.7505
Epoch 44/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0835 - val_accuracy: 0.8090 - val_loss: 0.8096
Epoch 45/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 47ms/step - accuracy: 0.9433 - loss: 0.1978 - val_accuracy: 0.8669 - val_loss: 0.5554
Epoch 46/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0474 - val_accuracy: 0.8669 - val_loss: 0.5513
Epoch 47/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 48ms/step - accuracy: 0.9283 - loss: 0.2087 - val_accuracy: 0.7349 - val_loss: 0.8569
Epoch 48/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0418 - val_accuracy: 0.7349 - val_loss: 0.8619
Epoch 49/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 48ms/step - accuracy: 0.8990 - loss: 0.3059 - val_accuracy: 0.9552 - val_loss: 0.1074
Epoch 50/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0412 - val_accuracy: 0.9558 - val_loss: 0.1058
Epoch 51/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 48ms/step - accuracy: 0.9296 - loss: 0.2221 - val_accuracy: 0.9386 - val_loss: 0.1931
Epoch 52/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.9392 - val_loss: 0.1931
Epoch 53/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 47ms/step - accuracy: 0.9380 - loss: 0.1856 - val_accuracy: 0.8921 - val_loss: 0.3908
Epoch 54/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4173 - val_accuracy: 0.8904 - val_loss: 0.4009
Epoch 55/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 44ms/step - accuracy: 0.9341 - loss: 0.2018 - val_accuracy: 0.8405 - val_loss: 0.6513
Epoch 56/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.8376 - val_loss: 0.6609
Epoch 57/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 45ms/step - accuracy: 0.9439 - loss: 0.1733 - val_accuracy: 0.8124 - val_loss: 0.9658
Epoch 58/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0523 - val_accuracy: 0.8135 - val_loss: 0.9607
Epoch 59/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 29s 45ms/step - accuracy: 0.9444 - loss: 0.1784 - val_accuracy: 0.8365 - val_loss: 1.1138
Epoch 60/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8325 - val_loss: 1.1449
Epoch 61/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 45ms/step - accuracy: 0.9389 - loss: 0.1852 - val_accuracy: 0.5548 - val_loss: 2.2832
Epoch 62/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.5588 - val_loss: 2.2254
Epoch 63/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 45ms/step - accuracy: 0.9496 - loss: 0.1722 - val_accuracy: 0.8910 - val_loss: 0.4246
Epoch 64/75
  1/653 ━━━━━━━━━━━━━━━━━━━━ 28s 44ms/step - accuracy: 0.8750 - loss: 0.12582024-11-14 21:52:56.241346: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.1258 - val_accuracy: 0.8921 - val_loss: 0.4232
Epoch 65/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 45ms/step - accuracy: 0.9469 - loss: 0.1514 - val_accuracy: 0.8508 - val_loss: 0.6454
Epoch 66/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0415 - val_accuracy: 0.8526 - val_loss: 0.6304
Epoch 67/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.9555 - loss: 0.1315 - val_accuracy: 0.9570 - val_loss: 0.1406
Epoch 68/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.1641 - val_accuracy: 0.9570 - val_loss: 0.1405
Epoch 69/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 46ms/step - accuracy: 0.9399 - loss: 0.1736 - val_accuracy: 0.8612 - val_loss: 0.3614
Epoch 70/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8537 - val_loss: 0.3824
Epoch 71/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 30s 47ms/step - accuracy: 0.9532 - loss: 0.1488 - val_accuracy: 0.7854 - val_loss: 0.9148
Epoch 72/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.3813 - val_accuracy: 0.7831 - val_loss: 0.9374
Epoch 73/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1383s 2s/step - accuracy: 0.9468 - loss: 0.1613 - val_accuracy: 0.8457 - val_loss: 0.8874
Epoch 74/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 0.8480 - val_loss: 0.8636
Epoch 75/75
653/653 ━━━━━━━━━━━━━━━━━━━━ 31s 47ms/step - accuracy: 0.9576 - loss: 0.1375 - val_accuracy: 0.9220 - val_loss: 0.2281
[INFO] evaluating network...
218/218 ━━━━━━━━━━━━━━━━━━━━ 2s 11ms/step 
              precision    recall  f1-score   support

       eight       1.00      0.56      0.72       193
        five       0.99      1.00      0.99       197
        four       1.00      0.90      0.95       184
        nine       1.00      0.87      0.93       207
         one       1.00      0.97      0.98       192
         six       0.66      1.00      0.79       194
         ten       0.97      1.00      0.99       208
       three       0.87      0.99      0.93       184
         two       1.00      1.00      1.00       184

    accuracy                           0.92      1743
   macro avg       0.94      0.92      0.92      1743
weighted avg       0.94      0.92      0.92      1743