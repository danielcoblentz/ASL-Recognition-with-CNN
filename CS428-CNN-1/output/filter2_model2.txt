[INFO] saving model...
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[INFO] serializing label encoder...
(CS428) dancoblentz@Dans-MacBook-Pro CS428-CNN-1 % python train_model.py -c config/config.json -f 2 -m 2 

TensorFlow version: 2.18.0
Filter 2 has been chosen
Model 2 has been chosen
CNN+ResBlock
[INFO] loading images...
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)      │ (None, 64, 64, 1)         │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_1 (Conv2D)             │ (None, 64, 64, 16)        │             800 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation (Activation)       │ (None, 64, 64, 16)        │               0 │ conv2d_1[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization           │ (None, 64, 64, 16)        │              64 │ activation[0][0]           │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_2 (Conv2D)             │ (None, 64, 64, 16)        │          12,560 │ batch_normalization[0][0]  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_1 (Activation)     │ (None, 64, 64, 16)        │               0 │ conv2d_2[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_1         │ (None, 64, 64, 16)        │              64 │ activation_1[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d (Conv2D)               │ (None, 64, 64, 16)        │              32 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add (Add)                     │ (None, 64, 64, 16)        │               0 │ batch_normalization_1[0][… │
│                               │                           │                 │ conv2d[0][0]               │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d (MaxPooling2D)  │ (None, 32, 32, 16)        │               0 │ add[0][0]                  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout (Dropout)             │ (None, 32, 32, 16)        │               0 │ max_pooling2d[0][0]        │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_4 (Conv2D)             │ (None, 32, 32, 32)        │           4,640 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_2 (Activation)     │ (None, 32, 32, 32)        │               0 │ conv2d_4[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_2         │ (None, 32, 32, 32)        │             128 │ activation_2[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_5 (Conv2D)             │ (None, 32, 32, 32)        │           9,248 │ batch_normalization_2[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_3 (Activation)     │ (None, 32, 32, 32)        │               0 │ conv2d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_3         │ (None, 32, 32, 32)        │             128 │ activation_3[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_3 (Conv2D)             │ (None, 32, 32, 32)        │             544 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_1 (Add)                   │ (None, 32, 32, 32)        │               0 │ batch_normalization_3[0][… │
│                               │                           │                 │ conv2d_3[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d_1               │ (None, 16, 16, 32)        │               0 │ add_1[0][0]                │
│ (MaxPooling2D)                │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_1 (Dropout)           │ (None, 16, 16, 32)        │               0 │ max_pooling2d_1[0][0]      │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_7 (Conv2D)             │ (None, 16, 16, 64)        │          18,496 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_4 (Activation)     │ (None, 16, 16, 64)        │               0 │ conv2d_7[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_4         │ (None, 16, 16, 64)        │             256 │ activation_4[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_8 (Conv2D)             │ (None, 16, 16, 64)        │          36,928 │ batch_normalization_4[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_5 (Activation)     │ (None, 16, 16, 64)        │               0 │ conv2d_8[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_5         │ (None, 16, 16, 64)        │             256 │ activation_5[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv2d_6 (Conv2D)             │ (None, 16, 16, 64)        │           2,112 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_2 (Add)                   │ (None, 16, 16, 64)        │               0 │ batch_normalization_5[0][… │
│                               │                           │                 │ conv2d_6[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ max_pooling2d_2               │ (None, 8, 8, 64)          │               0 │ add_2[0][0]                │
│ (MaxPooling2D)                │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_2 (Dropout)           │ (None, 8, 8, 64)          │               0 │ max_pooling2d_2[0][0]      │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ flatten (Flatten)             │ (None, 4096)              │               0 │ dropout_2[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, 128)               │         524,416 │ flatten[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_6 (Activation)     │ (None, 128)               │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_6         │ (None, 128)               │             512 │ activation_6[0][0]         │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_3 (Dropout)           │ (None, 128)               │               0 │ batch_normalization_6[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_1 (Dense)               │ (None, 10)                │           1,290 │ dropout_3[0][0]            │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 612,474 (2.34 MB)
 Trainable params: 611,770 (2.33 MB)
 Non-trainable params: 704 (2.75 KB)
None
/opt/anaconda3/envs/CS428/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 44ms/step - accuracy: 0.1646 - loss: 2.5786 - val_accuracy: 0.2168 - val_loss: 2.2654
Epoch 2/75
2024-11-22 19:27:01.858086: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
  1/468 ━━━━━━━━━━━━━━━━━━━━ 19s 43ms/step - accuracy: 0.5000 - loss: 1.9491/opt/anaconda3/envs/CS428/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self.gen.throw(typ, value, traceback)
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5000 - loss: 1.9491 - val_accuracy: 0.2240 - val_loss: 2.2491
Epoch 3/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 44ms/step - accuracy: 0.3160 - loss: 1.9133 - val_accuracy: 0.4640 - val_loss: 1.4103
Epoch 4/75
2024-11-22 19:27:23.422143: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.2500 - loss: 2.2756 - val_accuracy: 0.4704 - val_loss: 1.4066
Epoch 5/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 44ms/step - accuracy: 0.4136 - loss: 1.6539 - val_accuracy: 0.3632 - val_loss: 2.0501
Epoch 6/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.3750 - loss: 1.4301 - val_accuracy: 0.3648 - val_loss: 2.0617
Epoch 7/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 45ms/step - accuracy: 0.4856 - loss: 1.4183 - val_accuracy: 0.5416 - val_loss: 1.5882
Epoch 8/75
2024-11-22 19:28:06.986870: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.9216 - val_accuracy: 0.5400 - val_loss: 1.6594
Epoch 9/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 45ms/step - accuracy: 0.5655 - loss: 1.2449 - val_accuracy: 0.5952 - val_loss: 1.6660
Epoch 10/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.3750 - loss: 1.2130 - val_accuracy: 0.5888 - val_loss: 1.7127
Epoch 11/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 46ms/step - accuracy: 0.5875 - loss: 1.1552 - val_accuracy: 0.3688 - val_loss: 2.2066
Epoch 12/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.8429 - val_accuracy: 0.3632 - val_loss: 2.1976
Epoch 13/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 21s 46ms/step - accuracy: 0.6019 - loss: 1.1230 - val_accuracy: 0.4072 - val_loss: 4.3159
Epoch 14/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 1.0129 - val_accuracy: 0.4104 - val_loss: 4.1647
Epoch 15/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 46ms/step - accuracy: 0.6636 - loss: 0.9800 - val_accuracy: 0.5208 - val_loss: 2.4605
Epoch 16/75
2024-11-22 19:29:37.050532: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 0.9336 - val_accuracy: 0.5144 - val_loss: 2.5527
Epoch 17/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.7003 - loss: 0.8503 - val_accuracy: 0.5416 - val_loss: 2.0722
Epoch 18/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.3006 - val_accuracy: 0.5392 - val_loss: 2.0745
Epoch 19/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 46ms/step - accuracy: 0.7291 - loss: 0.8036 - val_accuracy: 0.7536 - val_loss: 0.9588
Epoch 20/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 0.4702 - val_accuracy: 0.7608 - val_loss: 0.9357
Epoch 21/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.7500 - loss: 0.7306 - val_accuracy: 0.7328 - val_loss: 1.1663
Epoch 22/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.8283 - val_accuracy: 0.7360 - val_loss: 1.1141
Epoch 23/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.7514 - loss: 0.7101 - val_accuracy: 0.8608 - val_loss: 0.4597
Epoch 24/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.5560 - val_accuracy: 0.8712 - val_loss: 0.4209
Epoch 25/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 50ms/step - accuracy: 0.7953 - loss: 0.6135 - val_accuracy: 0.8168 - val_loss: 0.7065
Epoch 26/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.7500 - loss: 0.6355 - val_accuracy: 0.8160 - val_loss: 0.7255
Epoch 27/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 26s 56ms/step - accuracy: 0.8025 - loss: 0.5917 - val_accuracy: 0.4944 - val_loss: 2.6349
Epoch 28/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 1.0000 - loss: 0.2384 - val_accuracy: 0.5056 - val_loss: 2.5148
Epoch 29/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 25s 54ms/step - accuracy: 0.8202 - loss: 0.5416 - val_accuracy: 0.7000 - val_loss: 0.9874
Epoch 30/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4958 - val_accuracy: 0.7064 - val_loss: 0.9583
Epoch 31/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 50ms/step - accuracy: 0.8256 - loss: 0.5079 - val_accuracy: 0.6328 - val_loss: 1.5521
Epoch 32/75
2024-11-22 19:32:51.548218: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.3366 - val_accuracy: 0.6272 - val_loss: 1.6120
Epoch 33/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 24s 52ms/step - accuracy: 0.8179 - loss: 0.5469 - val_accuracy: 0.8584 - val_loss: 0.4321
Epoch 34/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0717 - val_accuracy: 0.8640 - val_loss: 0.4088
Epoch 35/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 27s 58ms/step - accuracy: 0.8413 - loss: 0.4647 - val_accuracy: 0.3640 - val_loss: 5.3194
Epoch 36/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 1.0000 - loss: 0.1302 - val_accuracy: 0.3664 - val_loss: 5.0644
Epoch 37/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 24s 51ms/step - accuracy: 0.8354 - loss: 0.4520 - val_accuracy: 0.8160 - val_loss: 0.9983
Epoch 38/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4564 - val_accuracy: 0.8064 - val_loss: 1.0429
Epoch 39/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 28s 60ms/step - accuracy: 0.8557 - loss: 0.4294 - val_accuracy: 0.9472 - val_loss: 0.3089
Epoch 40/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 1.0000 - loss: 0.1322 - val_accuracy: 0.9488 - val_loss: 0.3136
Epoch 41/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 50ms/step - accuracy: 0.8755 - loss: 0.3682 - val_accuracy: 0.9216 - val_loss: 0.4210
Epoch 42/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 0.4646 - val_accuracy: 0.9216 - val_loss: 0.3954
Epoch 43/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.8801 - loss: 0.3702 - val_accuracy: 0.4784 - val_loss: 2.8858
Epoch 44/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.6250 - loss: 0.7792 - val_accuracy: 0.5040 - val_loss: 2.5930
Epoch 45/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.8770 - loss: 0.3611 - val_accuracy: 0.6280 - val_loss: 1.9161
Epoch 46/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.2026 - val_accuracy: 0.6584 - val_loss: 1.6554
Epoch 47/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.8874 - loss: 0.3558 - val_accuracy: 0.6680 - val_loss: 1.8465
Epoch 48/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7500 - loss: 0.2749 - val_accuracy: 0.6664 - val_loss: 1.8707
Epoch 49/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.9004 - loss: 0.3058 - val_accuracy: 0.9256 - val_loss: 0.2200
Epoch 50/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4362 - val_accuracy: 0.9192 - val_loss: 0.2397
Epoch 51/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.8865 - loss: 0.3734 - val_accuracy: 0.8864 - val_loss: 0.3659
Epoch 52/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.2178 - val_accuracy: 0.9280 - val_loss: 0.2813
Epoch 53/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.8977 - loss: 0.3244 - val_accuracy: 0.9352 - val_loss: 0.1719
Epoch 54/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4012 - val_accuracy: 0.9352 - val_loss: 0.1695
Epoch 55/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.9087 - loss: 0.2902 - val_accuracy: 0.7888 - val_loss: 0.7279
Epoch 56/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.3923 - val_accuracy: 0.7528 - val_loss: 0.9663
Epoch 57/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.9004 - loss: 0.3066 - val_accuracy: 0.9640 - val_loss: 0.1006
Epoch 58/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.9648 - val_loss: 0.0980
Epoch 59/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.9239 - loss: 0.2569 - val_accuracy: 0.9704 - val_loss: 0.1302
Epoch 60/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.2486 - val_accuracy: 0.9664 - val_loss: 0.1325
Epoch 61/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.9272 - loss: 0.2519 - val_accuracy: 0.9240 - val_loss: 0.3260
Epoch 62/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.4318 - val_accuracy: 0.9248 - val_loss: 0.3429
Epoch 63/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.9087 - loss: 0.3131 - val_accuracy: 0.9528 - val_loss: 0.3905
Epoch 64/75
2024-11-22 19:39:24.272288: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
	 [[{{node IteratorGetNext}}]]
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.9033 - val_accuracy: 0.9536 - val_loss: 0.3962
Epoch 65/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 48ms/step - accuracy: 0.9133 - loss: 0.2570 - val_accuracy: 0.9448 - val_loss: 0.5654
Epoch 66/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.5327 - val_accuracy: 0.9416 - val_loss: 0.5750
Epoch 67/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 23s 48ms/step - accuracy: 0.9260 - loss: 0.2533 - val_accuracy: 0.6256 - val_loss: 2.4238
Epoch 68/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.6384 - val_loss: 2.2069
Epoch 69/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 25s 54ms/step - accuracy: 0.9247 - loss: 0.2300 - val_accuracy: 0.8928 - val_loss: 0.5887
Epoch 70/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.8750 - loss: 0.2331 - val_accuracy: 0.9000 - val_loss: 0.5706
Epoch 71/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.9314 - loss: 0.2096 - val_accuracy: 0.9352 - val_loss: 0.4975
Epoch 72/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.1658 - val_accuracy: 0.9352 - val_loss: 0.5083
Epoch 73/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.9323 - loss: 0.2149 - val_accuracy: 0.9872 - val_loss: 0.0414
Epoch 74/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 1.0000 - loss: 0.0925 - val_accuracy: 0.9856 - val_loss: 0.0434
Epoch 75/75
468/468 ━━━━━━━━━━━━━━━━━━━━ 22s 47ms/step - accuracy: 0.9271 - loss: 0.2270 - val_accuracy: 0.8536 - val_loss: 0.5946
[INFO] evaluating network...
157/157 ━━━━━━━━━━━━━━━━━━━━ 2s 9ms/step  
              precision    recall  f1-score   support

       eight       0.97      1.00      0.98       125
        five       1.00      0.84      0.91       125
        four       0.78      0.81      0.80       125
        nine       0.97      0.87      0.92       125
         one       0.98      0.99      0.99       125
       seven       1.00      0.98      0.99       125
         six       0.53      1.00      0.69       125
       three       1.00      0.42      0.59       125
         two       0.70      0.65      0.67       125
        zero       1.00      0.98      0.99       125

    accuracy                           0.85      1250
   macro avg       0.89      0.85      0.85      1250
weighted avg       0.89      0.85      0.85      1250

[INFO] saving model...
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[INFO] serializing label encoder...
(CS428) dancoblentz@Dans-MacBook-Pro CS428-CNN-1 % 
